# 01. Ensemble 

## 1. 앙상블
- 여러 개의 모델을 결합해 하나의 모델보다 더 좋은 성능을 내도록 하는 기법
<img width="622" height="290" alt="image" src="https://github.com/user-attachments/assets/29b8381d-067f-4323-afb1-9db1a0a0d75b" />

## 2. No Free Lunch 이론
- 모든 문제에서 항상 성능이 좋은 단일 알고리즘은 존재하지 않는다는 정리
- 특정 데이터에서만 잘 작동하는 단일 모델보다는 다양한 모델의 강점을 결합해서 여러 상황에서도 안정적으로 좋은 성능을 낼 수 있는 새로운 모델 개발

## 3. Diversity 이론
- 서로 다른 관점을 가진 모델들을 좋바할수록 전체 모델의 성능이 높아질 수 있다는 정리
- 각 모델이 서로 다른 방식으로 데이터를 해석하고 예측한다면, 훨씬 더 강력한 예측력을 가질 수 있음

## 4. Bias-Variance Trade-off
### 이상적인 경우 (Low Bias, Low Variance)
<img width="349" height="315" alt="image" src="https://github.com/user-attachments/assets/f4b2acf3-5fc6-4744-aaae-8cd671c1ef2d" />

- 예측이 정답 주변에 모여있음 = 오차가 작고 안정적임
- 데이터의 복잡한 패턴을 잘 포착하면서, 불필요한 노이즈에 과하게 반응하지 않음
- 학습과 일반화가 균형을 이룸

### 1) 편향이 큰 경우 (High Bias, Low Variance)
- 예측이 한 쪽으로 일관되게 빗나감
- 모델이 너무 단순 -> 과소적합상태

### 2) 분산이 큰 경우 (Low Bias, High Variance)
- 예측이 정답 근처지만 산발적으로 흩어짐
- 모델이 너무 복잡함 -> 과적합 상태

<img width="356" height="336" alt="image" src="https://github.com/user-attachments/assets/2a927ea7-7c67-4597-9c34-e2b30556db2d" />

<img width="646" height="326" alt="image" src="https://github.com/user-attachments/assets/572ffe0a-2459-40d1-ab08-18fda06b7add" />

<img width="499" height="158" alt="image" src="https://github.com/user-attachments/assets/48d46c5c-947a-49a2-a034-33c4ef0f54a0" />

# 02. Voting

## 1. Voting
- 여러 개의 서로 다른 모델들의 예측 결과를 투표 방식으로 결합하는 방법

## 2. Hard Voting
- 각 모델이 예측한 클래스 중 많이 선택된 것을 최종 예측값으로 결정하는 다수결 방식
- 분류 문제에 주로 사용됨

## 3. Soft Voting
- 각 모델이 예측한 클래스의 확률 또는 예측값을 평균 -> 가장 높은 확률을 가진 클래스 선택
- 분류 뿐 아니라 회귀 문제에도 사용

<img width="842" height="370" alt="image" src="https://github.com/user-attachments/assets/668c39de-dd38-4eaf-98bc-bfbd1202d215" />

# 03. Bagging

## 1. Bagging
<img width="387" height="244" alt="image" src="https://github.com/user-attachments/assets/32952327-e774-42f6-9483-93a384650d32" />

- Bootstrap Aggregating의 줄임말
- 훈련 데이터셋에서 중복을 허용해 샘플링 : Bootstrap
- 동일한 모델을 학습시켜 예측 결과를 통함 : Aggregating

## 2. Bootstrap
- 모집다능로부터 중복을 허용해 표본을 추출하는 방식
- 전체 훈련 데이터셋에서 중복 허용 샘플링을 통해 여러 개의 훈련 데이터 셋을 만듦
<img width="598" height="132" alt="image" src="https://github.com/user-attachments/assets/8557b921-6712-45b9-b2c8-adb8211f9885" />

- 전체 데이터의 약 36.8%는 어떤 부트스트랩 샘플에도 포함되지 않음
- 부트스트랩 과정에서 한 번도 뽑히지 않은 데이터 : Out-of-Bag (OOB) 샘플
- OBB를 활용해 해당 모델의 전체 성능 평가 : Out-of-Bag (OOB) 평가

