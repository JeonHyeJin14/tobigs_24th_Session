# 01. What's XAI?
: 인간이 딥러닝 모델의 의사결정 과정을이해하고 신뢰할 있도록 하는 설명 가능한 인공지능 기술
- 인공지능이 왜 그런 결정을 내렸는지, 그 이유와 근거를 사람이 이해할 수 있도록 설명해주는 기술

## 1. INterpretability (해석 가능성)
- 모델 자체의 동작 방식을 이해하는 것을 의미함
 <img width="571" height="237" alt="image" src="https://github.com/user-attachments/assets/6132d09f-dbe7-42c2-bda6-7a90dee81fd2" />

- 선형 회귀처럼 전통적인 머신러닝 모델은 구조가 단순해서 해석하기 쉽지만 딥러닝 모델은 구조가 복잡해 해석하기 어려움
<img width="388" height="233" alt="image" src="https://github.com/user-attachments/assets/1982fbc9-0de5-4628-b1d9-4c6e26383a64" />

## 2. Explanation (설명)
- 모델이 내놓은 결과에 대한 이유를 설명하는 것
- XAI 방법론들은 이 설명을 제공하는 데 중점을 둔다.

# 02. Why XAI is important ?

## 1. AI Black Box Problem
: 인공지능 모델이 어떤 입력을 받아서 어떻게 처리해서 출력을 내놓는지 그 과정을 알 수 없는 현상
- 복잡한 딥러닝 모델은 수많은 계층과 복잡한 연결망으로 이루어져 있어서, 블랙박스처럼 그 내부에서 무슨 일이 일어나는지 이해하기가 매우 어려움
- 모델에 데이터를 넣고 결과만 볼 수 있을 뿐 어떻게? 그런 결과가 나왔는지 그 이유를 명확히 알기 힘들다.

### 문제점
1. 신뢰성부족 : 의료 진단이나 자율주행차처럼 중요한 분야에서 AI가 잘못된 결정을 내렸을 때 그 원인을 파악하고 수정하기 어려움
2. 공정성 문제 : AI가 특정 인종이나 성별에 대해 차별적인 겨로가를 내놓았을 때 , 왜 그런 편향이 생겼는지 알 수 없어서 해결이 힘들다
3. 법적 책임 소재 : AI 시스템에 의해 사고가 발생했을 경우, 그 책임이 누구에게 있는지 따지기가 애매해짐

### XAI 중요성
1. 투명성 향상
   - AI가 어떻게 결정을 내렸는지 그 과정을 투명하게 공개하면, 모델을 더 깊이 이해하고 신뢰할 수 있게 됨
   - 의료나 금융처럼 삶에 직접적인 영향을 미치는 분야에서는 투명성이 필수적
  
2. AI 성능 향상
   - XAI는 단순히 결과를 설명하는 데 그치지 않음. 모델이 왜 틀린 결정을 내렸는지 그 원인을 파악할 수 있게 해줌
3. 실제 적용
   - 예를 들어서 규제 당국이 AI 시스템의 법규 준수 여부를 평가할 때 XAI를 통해 모델의 작동 방식을 확인하고 검증할 수 있음

### XAI의 작동방식
<img width="686" height="177" alt="image" src="https://github.com/user-attachments/assets/96bd8df9-7191-400a-ae0e-0f4960cc8664" />

#### 이 이미지는 강아지가 기타를 치는 사진을 인공지능이 분석한 결과

a 원본이미지 : 기타를 치는 강아지 사진이 있음

AI 모델은 이 사진을 보고 가장 가능성이 높은 세 가지 항목을 예측함
1. 일렉트릭 기타 = 32%의 확률
2. 어쿠스틱 기타 = 24%의 확률
3. 래브라도 = 21%의 확률

