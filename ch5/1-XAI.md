# 01. What's XAI?
: 인간이 딥러닝 모델의 의사결정 과정을이해하고 신뢰할 있도록 하는 설명 가능한 인공지능 기술
- 인공지능이 왜 그런 결정을 내렸는지, 그 이유와 근거를 사람이 이해할 수 있도록 설명해주는 기술

## 1. INterpretability (해석 가능성)
- 모델 자체의 동작 방식을 이해하는 것을 의미함
 <img width="571" height="237" alt="image" src="https://github.com/user-attachments/assets/6132d09f-dbe7-42c2-bda6-7a90dee81fd2" />

- 선형 회귀처럼 전통적인 머신러닝 모델은 구조가 단순해서 해석하기 쉽지만 딥러닝 모델은 구조가 복잡해 해석하기 어려움
<img width="388" height="233" alt="image" src="https://github.com/user-attachments/assets/1982fbc9-0de5-4628-b1d9-4c6e26383a64" />

## 2. Explanation (설명)
- 모델이 내놓은 결과에 대한 이유를 설명하는 것
- XAI 방법론들은 이 설명을 제공하는 데 중점을 둔다.

# 02. Why XAI is important ?

## 1. AI Black Box Problem
: 인공지능 모델이 어떤 입력을 받아서 어떻게 처리해서 출력을 내놓는지 그 과정을 알 수 없는 현상
- 복잡한 딥러닝 모델은 수많은 계층과 복잡한 연결망으로 이루어져 있어서, 블랙박스처럼 그 내부에서 무슨 일이 일어나는지 이해하기가 매우 어려움
- 모델에 데이터를 넣고 결과만 볼 수 있을 뿐 어떻게? 그런 결과가 나왔는지 그 이유를 명확히 알기 힘들다.

### 문제점
1. 신뢰성부족 : 의료 진단이나 자율주행차처럼 중요한 분야에서 AI가 잘못된 결정을 내렸을 때 그 원인을 파악하고 수정하기 어려움
2. 공정성 문제 : AI가 특정 인종이나 성별에 대해 차별적인 겨로가를 내놓았을 때 , 왜 그런 편향이 생겼는지 알 수 없어서 해결이 힘들다
3. 법적 책임 소재 : AI 시스템에 의해 사고가 발생했을 경우, 그 책임이 누구에게 있는지 따지기가 애매해짐

### XAI 중요성
1. 투명성 향상
   - AI가 어떻게 결정을 내렸는지 그 과정을 투명하게 공개하면, 모델을 더 깊이 이해하고 신뢰할 수 있게 됨
   - 의료나 금융처럼 삶에 직접적인 영향을 미치는 분야에서는 투명성이 필수적
  
2. AI 성능 향상
   - XAI는 단순히 결과를 설명하는 데 그치지 않음. 모델이 왜 틀린 결정을 내렸는지 그 원인을 파악할 수 있게 해줌
3. 실제 적용
   - 예를 들어서 규제 당국이 AI 시스템의 법규 준수 여부를 평가할 때 XAI를 통해 모델의 작동 방식을 확인하고 검증할 수 있음

### XAI의 작동방식
<img width="686" height="177" alt="image" src="https://github.com/user-attachments/assets/96bd8df9-7191-400a-ae0e-0f4960cc8664" />

#### 이 이미지는 강아지가 기타를 치는 사진을 인공지능이 분석한 결과

a 원본이미지 : 기타를 치는 강아지 사진이 있음

AI 모델은 이 사진을 보고 가장 가능성이 높은 세 가지 항목을 예측함
1. 일렉트릭 기타 = 32%의 확률
2. 어쿠스틱 기타 = 24%의 확률
3. 래브라도 = 21%의 확률

# 02.Taxonomies of XAI

## 1. Scope of explanation (설명의 범위) : Global vs Local

### 1) Global(모델 전체 관점)
: 모델이 전반적으로 어떤 규칙을 학습 했는지, 특징(변수)들이 평균적으로 예측에 어떻게 기여하는지 설명
- 장점 : 정책/감사/모델 거버넌스에 유용함, 전체 행동 이해
- 주의점 : 사호작용/비선형성이 강하면 단변수 시각화 (PDP)가 왜곡될 수 이씅ㅁ, 변수 상관이 있으면 해석에 주의해야함
- 활용 : 규제 보고, 모델 선택/튜닝 기준, 조직 내 설명 책임

### 2) Local(사례별 관점)
: 특정 입력 xi에 대해 왜 그런 예측이 나왔는지 설명함
- 장점: 사용자 피드백/오류 분석/개별 의사결정 근거 제공
- 노이즈/불안정성/기여도 합산의 의미에 민감함
- 활용 : 개별 대출 승인 사유, 의료 영상 판독 근거, 모델 디버깅

## 2. Methodology(방법론)

### 1) Gradient-based (기울기 기반)
: 예측이 입력 변화에 얼마나 민감한지 계산
- 장점 : 빠르고 딥러닝 모델에 적합함
- 단점 : 노이즈, 기준점 선택에 민감함

### 2) Perturvation-based (교란 기반)
: 입력을 가리거나 바꾸고 결과 변화를 측정함
- 장점 : 모델 불문, 직관적
- 단점 : 계산량이 많음 , 변수 상관에 민감함

## 3. Dependency (모델 의존성)

### 1) Model-agnostic (모델 무관)
: 입력과 출력만 있으면 적용 가능
- 장점 : 어떤 모델에도 사용 가능
- 단점 : 근사 오차, 계산 느림

### 2) Model-specific (모델 특화)
- 특정 모델 구조를 활용한 기법
- 장점 : 빠르고 정확함
- 단점 : 다른 모델에는 적용불가

## 4. Quick Guide (어떻게 선택할까?)
- 이미지 분류 (CNN) : Grad-CAM (로컬, Gradient) + SHAP (Global, Perturvation)
- 트리 모델 (GBM/XGBoost) : TreeSHAP(Model-specific, 빠르고 정확)
- 텍스트/Transformer : Integrated Gradients , Token-level SHAP
- 블랙박스 모델 : LIME, Kernel SHAP (Model-agnostic)

# 03.XAI methods
